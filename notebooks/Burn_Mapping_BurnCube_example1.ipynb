{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated change detection and severity mapping using Digital Earth Australia - Worked example including technical details\n",
    "\n",
    "This script shows the workflow for change detection and severity mapping using the DEA Landsat data archive and the burn mapping tools developed by ANU. This notebook also provides details on the underlying concepts and theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve imagery from the DEA\n",
    "\n",
    "To illustrate the concepts used in this toolbox, we first need to load in a time series of Landsat imagery.\n",
    "To that end, we'll import the **BurnCube**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('/g/data/r78/DPIPWE_lm/dea-notebooks/10_Scripts'))\n",
    "sys.path.append(os.path.abspath('/g/data/r78/DPIPWE_lm/repos/burn-mapping/notebooks/handover'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datacube\n",
    "from BurnCube import BurnCube \n",
    "bc = BurnCube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `load_cube` function to extract Landsat data from the DEA and mask out cloud pixels\n",
    "The function takes several arguments:\n",
    "    \n",
    "    x: region in the x dimension (easting, EPSG 3577)\n",
    "    y: region in the y dimension (northing, EPSG 3577)\n",
    "    time: temporal extent\n",
    "    resolution: spatial resolution in m\n",
    "    landsat_numbers: Landsat sensors to be considered in list format, e.g. [5,7,8] or [8]\n",
    "\n",
    "Standard settings are:\n",
    "* projection is EPSG:3577 (GDA94 / Australian Albers). \n",
    "* product retrieved is `Landsat*\\_nbart_albers`\n",
    "* dates with less than 20% good-quality pixels for the region of interest will be ignored.\n",
    "\n",
    "These settings can not be changed through arguments but can be changed in the `load_cube` function in `BurnCube.py`.\n",
    "\n",
    "The example below will load imagery for  \n",
    "* 25 km by 25 km area \n",
    "* centered around provided latitude and longitude coordinates\n",
    "* at 25 m resolution \n",
    "* for a period defined by a start and end date (in `'yyyy-mm-dd'` string format)\n",
    "* with burn mapping to be undertaken for the last year of this time series.\n",
    "\n",
    "Note:\n",
    "* Latitude and longitude can be converted to GDA94 using the `Proj` function in the **prypoj** module.\n",
    "* Choosing a different resolution will require resampling and may increase processing time significantly.\n",
    "* Similarly, imagey can be requested in different coordinates but this, too, will increase processing time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "\n",
    "# provide center coordinates (longitude and latitude) \n",
    "# example relates to the Sir Ivan fire in 2017 around Uarbry in NSW\n",
    "lon =  148.1\n",
    "lat = -41.2\n",
    "\n",
    "# convert to projected centre coordinates\n",
    "wgs84 = pyproj.Proj(init='epsg:4326')\n",
    "gda94 = pyproj.Proj(init='epsg:3577')\n",
    "easting,northing = pyproj.transform(wgs84,gda94,lon,lat)\n",
    "\n",
    "# define projected region extent\n",
    "x = (easting+12500,easting-12500)   # 12,500 m is half of the required window size\n",
    "y = (northing+12500,northing-12500)\n",
    "res = (25, 25)  # resolution\n",
    "sensor = [7, 8]  # Landsat-8\n",
    "\n",
    "datatime = ('2017-01-01','2017-12-31') # period for extracting landsat data\n",
    "\n",
    "bc.load_cube(x, y, res, datatime, sensor) # return time series of good-quality imagery as 4D array with [band, time, y, x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(bc.dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflectance data check\n",
    "Below follows a code snippet to visualise some part of the data. This example shows NIR reflectance (band 3) for available images during the months before and after the fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.dataset.cube.sel(time=slice('2016-12-01','2017-04-01'))[3,:,:,:].plot.imshow(col='time',col_wrap = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the Normalized Burn Ratio (NBR)\n",
    "The Normalized Burn Ratio (NBR) is recommended for use in conjunction with the cosine distance to correctly identify significant reflectance changes that can be associated with fire events. \n",
    "NBR is calculated as:\n",
    "\n",
    "$NBR = \\frac{nir-swir2}{nir+swir2}$\n",
    "\n",
    "where _nir_ and _swir2_ refer to the Near Infrared (~840 nm) and Shortwave Infrared (~2200 nm) bands in the Landsat imagery.  \n",
    "\n",
    "Some example NBR maps are shown below. Low NBR values (which can be indicative of burning) are shown in blueish colours and high NBR values in reddish colours. White areas indicate pixels with data of insufficient quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example calculation of NBR\n",
    "NBR = (bc.dataset.cube[3,:,:,:]-bc.dataset.cube[5,:,:,:])/(bc.dataset.cube[3,:,:,:]+bc.dataset.cube[5,:,:,:])\n",
    "\n",
    "# plot NBR maps for a selected period\n",
    "NBR.sel(time=slice('2016-12-01','2017-04-01')).plot.imshow(col='time',col_wrap = 5,cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of geometric median  and cosine and euclidian distances\n",
    "\n",
    "We will use the `geomedian` function in the **BurnCube** module to calculate geometric median for a reference period. \n",
    "Subsequently, we will use the `distances` function in the **BurnCube** module to calculate the cosine distance and NBR Euclidean distance. \n",
    "\n",
    "\n",
    "The function `geomedian` returns the __geometric median__ of band reflectances for the reflectance datacube provided as  (Roberts *et al.*, 2017):\n",
    "\n",
    "$\\hat{m}: = argmin\\sum_{i=1}^{n}\\parallel x-x_i\\parallel_2$, $x\\in \\mathbb{R}^p$\n",
    "\n",
    "The function involves an iterative optimiser to find a numerical solution. The optimisation parameters can be configured, and the function supports distributed use of multiple CPUs for faster evaluation. Arguments are:\n",
    "\n",
    "    period: the period for which the geomedian is to be calculated, in format ('yyyy-mm-dd','yyy-mm-dd')\n",
    "    max_iter: maximum number of iterations \n",
    "    epsilon: tolerance stopping criterion    \n",
    "    n_procs: number of CPUs to be used \n",
    "\n",
    "\n",
    "The function `distances` returns two standardised distances as follows:\n",
    "\n",
    "The returned variable `cosdistance` is the __cosine distance__ between two spectra, _x_ and _y_, _i.e._, the reflectance time series data and the geometric median reflectance :\n",
    "\n",
    "$cosdist = 1-\\frac{\\sum_{i=1}^{p}x_iy_i}{\\sqrt{\\sum_{i=1}^{p}x_i^2\\sum_{i=1}^{p}y_i^2}}$\n",
    "\n",
    "where _p_ is the number of bands. The denominator is equivalent to the 'spectral angle'.\n",
    "\n",
    "The returned variable `nbr_eucdistance` is the __Euclidean distance in NBR space__ between the NBR time series and the median NBR (_NBRmed_) calculated from the geometric median:\n",
    "\n",
    "$NBRdist = \\sqrt{\\sum_{i=1}^{n}(NBR_i-NBRmed)^2}$\n",
    "\n",
    "where _n_ is the number of dates with imagery.\n",
    "The function supports distributed use of multiple CPUs for faster evaluation. Arguments are:\n",
    "\n",
    "    period: the period for which the distances are to be calculated, in format ('yyyy-mm-dd','yyy-mm-dd')\n",
    "    n_procs: number of CPUs to be used\n",
    "\n",
    "Use `help(function)` for  details on the usage of each function, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(bc.geomedian)\n",
    "help(bc.distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example calculation: geometric median\n",
    "The following example shows the calculation of the geometric median using 8 CPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = ('2013-01-01','2016-12-31') # period used for the calculation of geometric median\n",
    "bc.geomedian(period, n_procs=8) # this typically may take around 5 minutes for a region of 1000x1000 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geomedian is stored in a new attribute `geomed`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.geomed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of geomedian\n",
    "The following code generates an RGB composite with geometric median reflectances stretched the reflectance value to [0,255] using the internal function `stretch_RGB`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def stretch_RGB(data):\n",
    "    \"\"\"\n",
    "    stretch RGB to 0-1\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    tmp = data\n",
    "    a = (tmp-np.nanpercentile(tmp,1))/(np.nanpercentile(tmp,99.5)-np.nanpercentile(tmp,0.5))*255 \n",
    "    a[a>255]=255\n",
    "    a[a<0]=0\n",
    "    return a\n",
    "\n",
    "def RGB_plot(R, G, B):\n",
    "    import numpy as np\n",
    "    from PIL import Image   \n",
    "    rgbArray = np.zeros((R.shape[0],R.shape[1],3), 'uint8')\n",
    "    rgbArray[..., 0] = (stretch_RGB(R))\n",
    "    rgbArray[..., 1] = (stretch_RGB(G))\n",
    "    rgbArray[..., 2] = (stretch_RGB(B))\n",
    "    img = Image.fromarray(np.flipud(rgbArray))\n",
    "    return img.resize((500,500))\n",
    "\n",
    "#plot the geometric median reflectances as false colour composite: swir2, nir and green as R,G,B\n",
    "RGB_plot(bc.geomed.geomedian.data[5,:,:],bc.geomed.geomedian.data[3,:,:],bc.geomed.geomedian.data[1,:,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: calculating cosine distance and euclidian distances\n",
    "The following example shows the calculation of the distances together using 8 CPUs for the reference period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.distances(period, n_procs=8) # This step can take several minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine and Euclidian distances are stored along with actual NBR and NBR change direction in the attribute `bc.dists`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.dists "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier mapping\n",
    "Having calculated the cosine and NBR euclidian distance, we can calculate a distance _d_ for every pixel that corresponds to the threshold distance for an outlier. \n",
    "We the use quartile-based outlier criterion commonly used in box-and-whiskers plots, among others (Tukey, 1977): \n",
    "\n",
    "$ d > Q_{3}+1.5*{IQR} = Q_{3}+1.5(Q_{3}-Q_{1})$\n",
    "\n",
    "where $Q_1$ and $Q_3$ are the 1st and 3rd quartile (or 25th and 75th percentile), and _IQR_ is the interquartile range.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.outliers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance functions and outlier detection functions only need to be evaluated once for a given period and region of interest. The following examples show maps of the threshold values for `cosdist` and `nbr_ecudistance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.outlrs.CDistoutlier.plot.imshow(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.outlrs.NBRoutlier.plot.imshow(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burn severity mapping\n",
    "\n",
    "The function `severitymapping` from the **BurnCube** module is designed to map the extent and severity of likely burns. Outputs include two classes for burned area, namely high severity and moderate severity burns.\n",
    "\n",
    "Two methods are available for change and severity mapping using the difference thresholding scheme:\n",
    "\n",
    "1. `NBR` method: detects cosine distance outliers and requires that dNBR<0. Suitable for burn detection.Recommended for burn detection.\n",
    "\n",
    "2. `NBRdist` method: detects cosine distance outliers and NBR euclidean distance outliers, and requires a reduction in NBR. This method can detect more area with moderate burn.\n",
    "\n",
    "The default method is `NBR`. All pixels detected as burned area following this method are classified as 'high-severity' burns.\n",
    "\n",
    "An optional, and recommended, extension to the method is region-growing. This will include further areas that do not qualify as outliers but do show a substantial decrease in NBR and are adjoining pixels detected as burns. These pixels are classified as 'moderate severity burns'.\n",
    "\n",
    "Detected fire events derived from GA Sentinel Hotspots are used to provide *corroborating evidence* to confirm potential burn areas detected from the spectral observations. A buffer of 4-km wide is drawn around the detected fire location, to account for positional inaccuracies and the possibility that the fire may have spread before and after detection. \n",
    "\n",
    "Arguments of the function are:\n",
    "\n",
    "    mappingperiod: the period for which the geomedian is to be calculated, in format ('yyyy-mm-dd','yyy-mm-dd')\n",
    "    method: the method to be used ('NBR' or 'NBRdist') \n",
    "    growing: whether to extend the burn area mapping using region-growing (False/True)    \n",
    "\n",
    "The following example generates a burn severity map using the method 'NBR'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingperiod = ('2016-07-01','2017-06-30')\n",
    "bc.distances(mappingperiod,n_procs=8)\n",
    "out = bc.severitymapping(mappingperiod, method='NBR',growing=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data to a NetCDF file using `out.to_netcdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the output in netCDF\n",
    "out.to_netcdf('/home/554/lm4502/burn-mapping-master/BurnMapping_test_goshen2.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet below illustrates the respective areas classified as high-intensity burns only, moderate- or high-intensity burns, and areas for which corroborating evidence for burning exists from Sentinel Hotspots. \n",
    "The fourth figure shows the simple sum of the previous three binary images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,axes=plt.subplots(ncols=3,figsize=[16,5])\n",
    "#plot the high-severity burns \n",
    "cax1=out.Severe.plot.imshow(ax=axes[0],cmap='binary',add_colorbar=False)\n",
    "cax1.axes.set_title('high-severity burns',fontsize=18)\n",
    "cax1.axes.get_xaxis().set_visible(False)\n",
    "cax1.axes.get_yaxis().set_visible(False)\n",
    "#plot the moderate severity burns\n",
    "cax2=out.Moderate.plot.imshow(ax=axes[1],cmap='binary',add_colorbar=False)\n",
    "cax2.axes.set_title('moderate-severity burns',fontsize=18)\n",
    "cax2.axes.get_xaxis().set_visible(False)\n",
    "cax2.axes.get_yaxis().set_visible(False)\n",
    "#plot corroborating evidence from hotspots data\n",
    "cax3=out.Corroborate.plot.imshow(ax=axes[2],cmap='binary',add_colorbar=False)\n",
    "cax3.axes.set_title('corroborating evidence',fontsize=18)\n",
    "cax3.axes.get_xaxis().set_visible(False)\n",
    "cax3.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot both high and moderate burns with the hotspot data\n",
    "Allburnt = out.Severe+out.Moderate+out.Corroborate\n",
    "from matplotlib.colors import ListedColormap\n",
    "fig,axes=plt.subplots()\n",
    "cMap = ListedColormap(['white','darksalmon','red','firebrick'])\n",
    "cax=Allburnt.plot.imshow(cmap=cMap,levels=[0,1,2,3,4],add_colorbar=False)\n",
    "cax.axes.set_title('all burns and hotspot data',fontsize=18)\n",
    "cbar = fig.colorbar(cax,ticks=[0.5,1.5,2.5,3.5])\n",
    "cbar.ax.set_yticklabels(['unburned','corroborating evidence','moderate-severity burns','high-severity burns'])\n",
    "cax.axes.get_xaxis().set_visible(False)\n",
    "cax.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A comparison of the four panels shows there are areas \n",
    "* detected as burned but apparently well away from other mapped burn areas and without corroborating evidence from detected fires\n",
    "* detected as burned that are more than 4-km away from detected fires but that adjoing corroborated burn areas.\n",
    "\n",
    "An example of how to validate severity mapping is included in the notebook `Validation_example1.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
