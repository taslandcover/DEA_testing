{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Single Date by Polygons\n",
    "This notebook is designed to iterate through a polygon shapefile and extract image chips based on the fields in the attribute table realting to capture date and sensor mission. This notebook will only extract a bounding rectangle for each shape (incuding multipart shapes rather than an exact polygon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.drivers.netcdf import write_dataset_to_netcdf\n",
    "import geopandas as gpd\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../Tools/')\n",
    "from dea_tools.datahandling import download_unzip\n",
    "from dea_tools.datahandling import load_ard\n",
    "from dea_tools.plotting import rgb\n",
    "from dea_tools.spatial import xr_rasterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='Polygon_LUT_query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input LUT polygon file\n",
    "LUT_polygon = '/home/jovyan/DPIPWE_input/DEA_multi__sen_shapes.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SENSOR</th>\n",
       "      <th>SEN_DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SENTINEL</td>\n",
       "      <td>2019-11-16</td>\n",
       "      <td>Jilletts Tier</td>\n",
       "      <td>POLYGON ((501065.355 5346765.939, 503843.485 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LANDSAT</td>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>Boobyalla</td>\n",
       "      <td>POLYGON ((574145.622 5473413.415, 576295.366 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>SENTINEL</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>Flinders_multi</td>\n",
       "      <td>MULTIPOLYGON (((600923.053 5550302.147, 599600...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    SENSOR    SEN_DATE            NAME  \\\n",
       "0   0  SENTINEL  2019-11-16   Jilletts Tier   \n",
       "1   0   LANDSAT  2019-01-29       Boobyalla   \n",
       "2   0  SENTINEL  2019-01-30  Flinders_multi   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((501065.355 5346765.939, 503843.485 5...  \n",
       "1  POLYGON ((574145.622 5473413.415, 576295.366 5...  \n",
       "2  MULTIPOLYGON (((600923.053 5550302.147, 599600...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read unzipped shapefile\n",
    "gdf = gpd.read_file(LUT_polygon)\n",
    "\n",
    "# Check that the polygon loaded as expected. We'll just print the first 3 rows to check\n",
    "gdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise analysis parameters (not really necessary)\n",
    "sdate = '' #start date\n",
    "edate = '' #end date\n",
    "name = '' #name attribute to label output \n",
    "product = '' #attribute value for product/sensor\n",
    "\n",
    "#measurements = ['nbart_red', 'nbart_green', 'nbart_blue', 'nbart_nir'] #assess how to handle Landsat v Sentinel\n",
    "crs = gdf.crs\n",
    "#align = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1/3\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Loading 1 time steps\n",
      "Feature: 2/3\n",
      "Finding datasets\n",
      "    ['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3']\n",
      "Loading 1 time steps\n",
      "Feature: 3/3\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Loading 1 time steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.8/site-packages/datacube/utils/geometry/_base.py:608: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  return type(geom)([segmentize_shapely(g) for g in geom])\n",
      "/env/lib/python3.8/site-packages/datacube/utils/geometry/_base.py:608: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  return type(geom)([segmentize_shapely(g) for g in geom])\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to ve results\n",
    "results = {} \n",
    "\n",
    "# Loop through polygons in geodataframe (gdf) and extract satellite data\n",
    "for index, row in gdf.iterrows():\n",
    "    \n",
    "    print(f'Feature: {index + 1}/{len(gdf)}')\n",
    "    \n",
    "    # Extract the feature's geometry as a datacube geometry object\n",
    "    geom = geometry.Geometry(geom=row.geometry, crs=gdf.crs)\n",
    "    sen = (row['SENSOR'])\n",
    "    sdate = (row['SEN_DATE'])\n",
    "    name = (row['NAME'])\n",
    "    \n",
    "    if sen == 'SENTINEL':\n",
    "        # Load available data from both Sentinel 2 satellites\n",
    "        products=['s2a_ard_granule', 's2b_ard_granule']\n",
    "        measurements=['nbart_blue', 'nbart_green', 'nbart_red', 'nbart_nir_1'] #For 10m false colour\n",
    "        resolution = (-10, 10) #For 10m false colour\n",
    "        #measurements=['nbart_blue', 'nbart_green', 'nbart_red', 'nbart_swir_2']\n",
    "        #resolution = (-20, 20)\n",
    "                \n",
    "    elif sen == 'LANDSAT':\n",
    "        products=['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3'],\n",
    "        measurements=['nbart_blue', 'nbart_green', 'nbart_red', 'nbart_nir', 'nbart_swir_1']\n",
    "        resolution = (-30, 30)\n",
    "        \n",
    "    else:\n",
    "        print('Sensor not recognised. No data loaded')\n",
    "    \n",
    "    #print(crs)\n",
    "    query = {'geopolygon': geom,\n",
    "         'time': sdate,\n",
    "         'measurements': measurements,\n",
    "         'resolution': resolution,\n",
    "         'output_crs':crs\n",
    "         }\n",
    "    #print(query)\n",
    "    \n",
    "    # Load data (can also use 'load_ard' (will mask clouds))\n",
    "    ds = load_ard(dc=dc, \n",
    "              products=products,\n",
    "              # min_gooddata=0.99,  # only take uncloudy scenes\n",
    "              mask_pixel_quality=False, # change for cloud masking\n",
    "              #ls7_slc_off = False, # Default takes slc\n",
    "              group_by= 'solar_day',\n",
    "              **query)\n",
    "    ''' \n",
    "    # Can use dc.load to load derived products\n",
    "    ds = dc.load(product=products, group_by= 'solar_day', **query)\n",
    "    '''\n",
    "    # Mask the dataset to our polygon boundary\n",
    "    # Create a mask of the indexed polygon\n",
    "    mask = xr_rasterize(gdf.iloc[[index]], ds)\n",
    "    \n",
    "    # Mask dataset to set pixels outside the polygon to `NaN`\n",
    "    ds_masked = ds.where(mask)\n",
    "    \n",
    "    # Append results to a dictionary using the name\n",
    "    # column as an key\n",
    "    results.update({name: ds_masked})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through dictionary and export to COG\n",
    "for key, value in results.items():    \n",
    "    item_da = value.isel(time=0).to_array() # Need to convert to array\n",
    "    write_cog(geo_im=item_da,\n",
    "          fname= key+'.tif',\n",
    "          overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
